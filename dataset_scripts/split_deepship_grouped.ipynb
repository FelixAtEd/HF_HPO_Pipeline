{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b150ad3d-dd42-4c7b-8cc4-1ee81347241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import pandas as pd\n",
    "from rich.pretty import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cfd3b8f-4a07-4542-ae32-f847e03e48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = \"/disk/scratch4/felix/data_sets/my_datasets/deepship/Data/wav_list_with_meta.csv\"\n",
    "df = pd.read_csv(\"/disk/scratch4/felix/data_sets/my_datasets/deepship/Data/wav_list_with_meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c38f9d3-e552-47c2-97be-53660d10d6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ships appearing in multiple Class\n"
     ]
    }
   ],
   "source": [
    "ship_labels = df.groupby('Shipname')['Class'].nunique().reset_index()\n",
    "duplicates = ship_labels[ship_labels['Class'] > 1]\n",
    "if not duplicates.empty:\n",
    "    print(\"Ships appearing in multiple labels:\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"No ships appearing in multiple Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ef74cf-d572-4515-87d9-942cf811804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Duration: 33610.0 seconds\n",
      "  Cargo: 5827.0 seconds, Assigned file paths: ['Cargo/20171104-1/1.wav', 'Cargo/20171124c-42/134001.wav', 'Cargo/20171205g-73/124454.wav', 'Cargo/20171125e-48/234924.wav', 'Cargo/20171121c-32/111158.wav', 'Cargo/20171130-57/165031.wav', 'Cargo/20171125c-46/134833.wav', 'Cargo/20171202e-64/141802.wav', 'Cargo/20171126b-51/044753.wav', 'Cargo/20171129c-56/075459.wav', 'Cargo/103.wav', 'Cargo/41.wav', 'Cargo/69.wav', 'Cargo/110.wav']\n",
      "  Passengership: 13305.0 seconds, Assigned file paths: ['Passengership/20180926-190/011928.wav', 'Passengership/20160603-15/042208.wav', 'Passengership/20160625a-22/041906.wav', 'Passengership/20160820a-33/33.wav', 'Passengership/20180511-165/101015.wav', 'Passengership/20180329-150/181312.wav', 'Passengership/20170906-115/104632.wav', 'Passengership/20180828a-181/125034.wav', 'Passengership/20160507a-4/4.wav', 'Passengership/20160629b-24/135359.wav', 'Passengership/20180215-144/185044.wav', 'Passengership/20161214-50/50.wav', 'Passengership/20180219-145/034422.wav', 'Passengership/20160616b-21/200904.wav', 'Passengership/20160506-2/2.wav', 'Passengership/20170330-61/175151.wav', 'Passengership/20180213-143/234934.wav', 'Passengership/20160507c-6/6.wav', 'Passengership/20170114-53/053615.wav', 'Passengership/20180506-162/054035.wav', 'Passengership/20161019a-46/174803.wav', 'Passengership/20180827-180/182309.wav', 'Passengership/20180821-18/153439.wav', 'Passengership/20180905c-183/212331.wav', 'Passengership/20180313a-147/181647.wav', 'Passengership/20180426-156/114757.wav', 'Passengership/20160528-12/12.wav', 'Passengership/20180320-148/103759.wav', 'Passengership/20180926a-191/012514.wav', 'Passengership/20181003-193/012519.wav', 'Passengership/20180711-178/094820.wav', 'Passengership/20160522-11/182048.wav', 'Passengership/20170615-93/124844.wav', 'Passengership/20180524-172/225612.wav', 'Passengership/20170401-63/000636.wav', 'Passengership/20180915-78/062231.wav', 'Passengership/20180912-25/034620.wav', 'Passengership/20160806-30/30.wav', 'Passengership/20171105-126/235036.wav', 'Passengership/20171106a-128/184906.wav', 'Passengership/20180722-179/181231.wav', 'Passengership/20180914-185/182348.wav', 'Passengership/20180514-167/181453.wav', 'Passengership/20180503-159/153434.wav', 'Passengership/20180502-158/030648.wav', 'Passengership/20180905b-182/061547.wav', 'Passengership/20170701-100/013614.wav', 'Passengership/20180925-189/012450.wav', 'Passengership/20160505-1/1.wav', 'Passengership/20161102-48/124450.wav', 'Passengership/20180913-184/181821.wav', 'Passengership/20171207-133/162949.wav', 'Passengership/20160521a-10/041411.wav', 'Passengership/20180518-168/031804.wav', 'Passengership/20160629a-23/23.wav', 'Passengership/20180923-188/012316.wav', 'Passengership/20160604-16/16.wav', 'Passengership/20180630-175/094326.wav', 'Passengership/20160909-41/41.wav', 'Passengership/20161028a-47/224803.wav', 'Passengership/20180929-192/012612.wav', 'Passengership/20180921-186/111213.wav', 'Passengership/20160506d-3/3.wav', 'Passengership/20161208-49/163603.wav', 'Passengership/29.wav', 'Passengership/14.wav', 'Passengership/32.wav', 'Passengership/37.wav']\n",
      "  Tanker: 8959.0 seconds, Assigned file paths: ['Tanker/20161128-58/005608.wav', 'Tanker/20160714-25/111759.wav', 'Tanker/20161002-40/130331.wav', 'Tanker/20160616-15/214515.wav', 'Tanker/20161009-42/42.wav', 'Tanker/20160509-1/123109.wav', 'Tanker/20160619-17/173821.wav', 'Tanker/20180421-194/025328.wav', 'Tanker/20180418-193/004704.wav', 'Tanker/20171204-156/222708.wav', 'Tanker/20160604-11/171238.wav', 'Tanker/20160526-6/6.wav', 'Tanker/20160910-37/190037.wav', 'Tanker/20160710-23/104049.wav', 'Tanker/20170920-139/232910.wav', 'Tanker/20171013-142/115050.wav', 'Tanker/20180507-202/212341.wav', 'Tanker/20160531-7/142749.wav', 'Tanker/20180425-199/083048.wav', 'Tanker/20160612-12/12.wav', 'Tanker/20160617-16/225229.wav', 'Tanker/20160515-3/020119.wav', 'Tanker/20161027-46/145435.wav', 'Tanker/20180211-178/180933.wav', 'Tanker/43.wav', 'Tanker/49.wav', 'Tanker/30.wav', 'Tanker/8.wav', 'Tanker/35.wav', 'Tanker/32.wav', 'Tanker/18.wav']\n",
      "  Tug: 5519.0 seconds, Assigned file paths: ['Tug/20171127a-24/105442.wav', 'Tug/20171209-48/041322.wav', 'Tug/20171213a-52/071716.wav', 'Tug/20171231a-70/215301.wav', 'Tug/20171207b-47/114556.wav', 'Tug/20171213-51/065742.wav', 'Tug/49.wav']\n",
      "\n",
      "Validation Duration: 4992.0 seconds\n",
      "  Cargo: 959.0 seconds, Assigned file paths: ['Cargo/99.wav', 'Cargo/27.wav', 'Cargo/15.wav', 'Cargo/38.wav', 'Cargo/78.wav']\n",
      "  Passengership: 1769.0 seconds, Assigned file paths: ['Passengership/20160515-8/8.wav', 'Passengership/20180917-81/035007.wav', 'Passengership/20180505a-161/101511.wav', 'Passengership/20160514-7/113853.wav', 'Passengership/20170331-62/044959.wav', 'Passengership/20180905a-19/211808.wav', 'Passengership/20180506b-164/113050.wav', 'Passengership/20180703-177/221012.wav', 'Passengership/20160516a-9/9.wav', 'Passengership/20160507b-5/5.wav', 'Passengership/20170503c-70/201813.wav', 'Passengership/20180922-187/124737.wav', 'Passengership/20170915-119/210154.wav', 'Passengership/27.wav', 'Passengership/31.wav']\n",
      "  Tanker: 1401.0 seconds, Assigned file paths: ['Tanker/20180316-185/163653.wav', 'Tanker/20160602a-10/10.wav', 'Tanker/20160519-5/5.wav', 'Tanker/20161022-44/030503.wav', 'Tanker/20180314-183/155725.wav', 'Tanker/20171015-144/090640.wav', 'Tanker/20171222a-161/152008.wav', 'Tanker/20.wav', 'Tanker/2.wav', 'Tanker/47.wav', 'Tanker/33.wav', 'Tanker/48.wav', 'Tanker/14.wav', 'Tanker/41.wav', 'Tanker/39.wav', 'Tanker/38.wav', 'Tanker/50.wav', 'Tanker/9.wav', 'Tanker/21.wav', 'Tanker/19.wav']\n",
      "  Tug: 863.0 seconds, Assigned file paths: ['Tug/20171221a-62/144544.wav', 'Tug/40.wav', 'Tug/9.wav']\n",
      "\n",
      "Test Duration: 6345.0 seconds\n",
      "  Cargo: 948.0 seconds, Assigned file paths: ['Cargo/20171124d-43/161634.wav', 'Cargo/96.wav', 'Cargo/62.wav', 'Cargo/44.wav']\n",
      "  Passengership: 2204.0 seconds, Assigned file paths: ['Passengership/20180617-173/201949.wav', 'Passengership/20180619-174/062048.wav', 'Passengership/20180513-166/084039.wav', 'Passengership/20171208d-134/023937.wav', 'Passengership/20180520-170/120550.wav', 'Passengership/20170527-86/013032.wav', 'Passengership/20180506a-163/105313.wav', 'Passengership/20170616-94/174832.wav', 'Passengership/20171106-127/044551.wav', 'Passengership/20170430-69/011712.wav', 'Passengership/20160606-17/17.wav']\n",
      "  Tanker: 1541.0 seconds, Assigned file paths: ['Tanker/20160714a-26/141202.wav', 'Tanker/20160613-13/13.wav', 'Tanker/20161024-45/061514.wav', 'Tanker/20170901-137/205515.wav', 'Tanker/20180311-182/212409.wav', 'Tanker/29.wav', 'Tanker/24.wav']\n",
      "  Tug: 1652.0 seconds, Assigned file paths: ['Tug/20171219a-60/210546.wav', 'Tug/20171230a-69/163503.wav']\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "ship_durations = df.groupby([\"Class\", \"Shipname\"])[\"Duration\"].sum().reset_index()\n",
    "\n",
    "ship_durations = ship_durations.sort_values(by=\"Duration\", ascending=True)\n",
    "\n",
    "\n",
    "# Split the Ships into train, validation, and test sets for each class\n",
    "def split_ships_by_class_and_duration(\n",
    "    ship_durations, test_size=0.2, val_size=0.2, random_state=42\n",
    "):\n",
    "    train_ships = {}\n",
    "    val_ships = {}\n",
    "    test_ships = {}\n",
    "\n",
    "    for class_ in ship_durations[\"Class\"].unique():\n",
    "        class_data = ship_durations[ship_durations[\"Class\"] == class_]\n",
    "\n",
    "        # Calculate target durations for each split\n",
    "        total_duration = class_data[\"Duration\"].sum()\n",
    "        test_duration = total_duration * test_size\n",
    "        val_duration = total_duration * val_size\n",
    "\n",
    "        # Initialize splits\n",
    "        train_ships[class_] = []\n",
    "        val_ships[class_] = []\n",
    "        test_ships[class_] = []\n",
    "\n",
    "        current_train_duration = 0\n",
    "        current_val_duration = 0\n",
    "        current_test_duration = 0\n",
    "\n",
    "        for _, row in class_data.iterrows():\n",
    "            ship = row[\"Shipname\"]\n",
    "            duration = row[\"Duration\"]\n",
    "            if current_val_duration < val_duration:\n",
    "                val_ships[class_].append(ship)\n",
    "                current_val_duration += duration\n",
    "            elif current_test_duration < test_duration:\n",
    "                test_ships[class_].append(ship)\n",
    "                current_test_duration += duration\n",
    "            else:\n",
    "                train_ships[class_].append(ship)\n",
    "                current_train_duration += duration\n",
    "\n",
    "    return train_ships, val_ships, test_ships\n",
    "\n",
    "\n",
    "# Perform the split\n",
    "train_ships, val_ships, test_ships = split_ships_by_class_and_duration(\n",
    "    ship_durations, test_size=0.1, val_size=0.1\n",
    ")\n",
    "\n",
    "# Assign rows to splits based on Ship and Class\n",
    "train_df = df[df.apply(lambda row: row[\"Shipname\"] in train_ships[row[\"Class\"]], axis=1)]\n",
    "val_df = df[df.apply(lambda row: row[\"Shipname\"] in val_ships[row[\"Class\"]], axis=1)]\n",
    "test_df = df[df.apply(lambda row: row[\"Shipname\"] in test_ships[row[\"Class\"]], axis=1)]\n",
    "\n",
    "def make_relative_path(path, class_name):\n",
    "    # Split path into parts\n",
    "    parts = path.split('/')\n",
    "    \n",
    "    # Remove the class from the path and return the rest\n",
    "    if parts[0].lower() == class_name:\n",
    "        return os.path.join(*parts[1:])  # Join the remaining parts relative to the class\n",
    "    return path  # In case something goes wrong (unexpected path format)\n",
    "\n",
    "# Print duration details for each split\n",
    "def print_duration_details(df, split_name):\n",
    "    total_duration = df[\"Duration\"].sum()\n",
    "    print(f\"\\n{split_name} Duration: {total_duration} seconds\")\n",
    "\n",
    "    # Ensure all classes are included, even if duration is 0\n",
    "    classes = sorted(df[\"Class\"].unique())\n",
    "    for class_ in classes:\n",
    "        # Get the duration for this class in the split\n",
    "        class_duration = df[df[\"Class\"] == class_][\"Duration\"].sum()\n",
    "\n",
    "        # Get the file path parts for this class\n",
    "        class_paths = df[df[\"Class\"] == class_][\"Filename\"].tolist()\n",
    "\n",
    "        # Convert paths to be relative to the class folder\n",
    "        relative_paths = [make_relative_path(path, class_) for path in class_paths]\n",
    "\n",
    "        # Print class details\n",
    "        print(f\"  {class_}: {class_duration} seconds, Assigned file paths: {relative_paths}\")\n",
    "\n",
    "train_df.to_csv(\"grouped_train.csv\", index=False)\n",
    "val_df.to_csv(\"grouped_validation.csv\", index=False)\n",
    "test_df.to_csv(\"grouped_test.csv\", index=False)\n",
    "\n",
    "print_duration_details(train_df, \"Train\")\n",
    "print_duration_details(val_df, \"Validation\")\n",
    "print_duration_details(test_df, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e654bfc-6eef-40d1-bdf0-6e99e349019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "assert len(set(train_df[\"Shipname\"]) & set(val_df[\"Shipname\"])) == 0, \"Ships overlap between Train and Validation!\"\n",
    "assert len(set(train_df[\"Shipname\"]) & set(test_df[\"Shipname\"])) == 0, \"Ships overlap between Train and Test!\"\n",
    "assert len(set(val_df[\"Shipname\"]) & set(test_df[\"Shipname\"])) == 0, \"Ships overlap between Validation and Test!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
