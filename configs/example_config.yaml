
# Any configuration file entries can be overridden by command line arguments.
# Example launch command:
# accelerate launch --gpu_ids="0" --num_processes=1 --mixed_precision=fp16 recipes/lora.py --config configs/audio_deepship.yaml 

# === Model Configuration ===
model_args:
  model_name_or_path:  MIT/ast-finetuned-audioset-10-10-0.448-v2
  # Simon-Kotchou/ssast-small-patch-audioset-16-16
  # facebook/wav2vec2-base
  # facebook/data2vec-audio-base
  # MIT/ast-finetuned-audioset-10-10-0.448-v2
  # Simon-Kotchou/ssast-small-patch-audioset-16-16
  # Vision Models:
  # "microsoft/resnet-50" 
  # "microsoft/resnet-18" 
  config_name: null  # Use default config from model
  task: "audio-classification" # image-classification
  sampling_rate: 16000
  cache_dir: ".cache"  # Avoid AFS time-out issues
  ignore_mismatched_sizes: true
  do_normalize: true


# === Dataset Configuration ===
dataset_args:
  dataset_name: "DEEPSHIP"
  audio_column_name: "input_values" # Must matches csv column name
  label_column_name: "labels" # Must matches csv column name
  max_length_seconds: 30.0
  
  # Optional dataset constraints:
  # max_train_samples: null
  # max_eval_samples: null


# === Training Configuration ===
training_args:
  # Directory & Device Settings
  output_dir: "./output"
  overwrite_output_dir: true
  local_rank: -1
  fp16: true

  # Training Schedule
  max_steps: 5000
  per_device_train_batch_size: 64
  per_device_eval_batch_size: 64
  gradient_accumulation_steps: 1
  gradient_checkpointing: false # Can be set to true for transformer models
  warmup_ratio: 0.1
  weight_decay: 0 
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1e-8

  # Evaluation & Logging
  eval_strategy: "steps"
  eval_steps: 100
  logging_steps: 10
  save_steps: 100
  save_total_limit: 3
  load_best_model_at_end: true
  metric_for_best_model: "eval_recall"
  greater_is_better: true

  # Additional Settings
  seed: 42
  label_names: "labels"
  log_level_replica: critical
  do_train: true
  do_eval: true
  do_predict: true
  dataloader_num_workers: 4

# === Hyperparameter Search ===
hyperparameter_search_space_args:
  backend: "optuna"
  direction: "maximize"  # Must match metric_for_best_model
  n_trials: 20
  lr_min: 1e-8
  lr_max: 1e-1